layers
======

.. only:: html

  Classes
  -------

  `class Add <layers/Add.html>`_
  : Layer to add a sequence of inputs.

  `class AveragePooling1D <layers/AveragePooling1D.html>`_
  : 1D average pooling layer.

  `class AveragePooling2D <layers/AveragePooling2D.html>`_
  : 2D average pooling layer.

  `class AveragePooling3D <layers/AveragePooling3D.html>`_
  : 3D average pooling layer.

  `class BatchNormalization <layers/BatchNormalization.html>`_
  : Batch normalization layer.
  `[Ioffe & Szegedy, 2015] <https://arxiv.org/abs/1502.03167>`_.

  `class Concatenate <layers/Concatenate.html>`_
  : Layer to concatenate a sequence of inputs.

  `class Conv1D <layers/Conv1D.html>`_
  : 1D convolution layer.

  `class Conv1DTranspose <layers/Conv1DTranspose.html>`_
  : 1D deconvolution layer.

  `class Conv2D <layers/Conv2D.html>`_
  : 2D convolution layer.

  `class Conv2DTranspose <layers/Conv2DTranspose.html>`_
  : 2D deconvolution layer.

  `class Conv3D <layers/Conv3D.html>`_
  : 3D convolution layer.

  `class Conv3DTranspose <layers/Conv3DTranspose.html>`_
  : 3D deconvolution layer.

  `class Dense <layers/Dense.html>`_
  : Fully-connected layer.

  `class DepthwiseConv2D <layers/DepthwiseConv2D.html>`_
  : 2D depthwise convolution layer.
  `[Chollet, 2016] <https://arxiv.org/abs/1610.02357>`_.

  `class Dropout <layers/Dropout.html>`_
  : Layer to apply the dropout function.
  `[Srivastava et.al, 2014] <http://jmlr.org/papers/v15/srivastava14a.html>`_.

  `class ELU <layers/ELU.html>`_
  : Layer to apply the exponential linear unit.
  `[Clevert et.al, 2015] <https://arxiv.org/abs/1511.07289>`_.

  `class Flatten <layers/Flatten.html>`_
  : Layer to reshape input into a matrix.

  `class GlobalAveragePooling1D <layers/GlobalAveragePooling1D.html>`_
  : 1D global average pooling layer.

  `class GlobalAveragePooling2D <layers/GlobalAveragePooling2D.html>`_
  : 2D global average pooling layer.

  `class GlobalAveragePooling3D <layers/GlobalAveragePooling3D.html>`_
  : 3D global average pooling layer.

  `class GlobalMaxPool1D <layers/GlobalMaxPool1D.html>`_
  : 1D global max pooling layer.

  `class GlobalMaxPool2D <layers/GlobalMaxPool2D.html>`_
  : 2D global max pooling layer.

  `class GlobalMaxPool3D <layers/GlobalMaxPool3D.html>`_
  : 3D global max pooling layer.

  `class Layer <layers/Layer.html>`_
  : The base class of layers.

  `class LeakyReLU <layers/LeakyReLU.html>`_
  : Layer to apply the leaky rectified linear unit.

  `class Maximum <layers/Maximum.html>`_
  : Layer to compute the maximum of a sequence of inputs.

  `class MaxPool1D <layers/MaxPool1D.html>`_
  : 1D max pooling layer.

  `class MaxPool2D <layers/MaxPool2D.html>`_
  : 2D max pooling layer.

  `class MaxPool3D <layers/MaxPool3D.html>`_
  : 3D max pooling layer.

  `class Minimum <layers/Minimum.html>`_
  : Layer to compute the minimum of a sequence of inputs.

  `class Multiply <layers/Multiply.html>`_
  : Layer to multiply a sequence of inputs.

  `class Permute <layers/Permute.html>`_
  : Layer to permute the dimensions of input.

  `class Reshape <layers/Reshape.html>`_
  : Layer to change the dimensions of input.

  `class ReLU <layers/ReLU.html>`_
  : Layer to apply the rectified linear unit.
  `[Nair & Hinton, 2010] <http://www.csri.utoronto.ca/~hinton/absps/reluICML.pdf>`_.

  `class SELU <layers/SELU.html>`_
  : Layer to apply the scaled exponential linear unit.
  `[Klambauer et.al, 2017] <https://arxiv.org/abs/1706.02515>`_.

  `class Softmax <layers/Softmax.html>`_
  : Layer to apply the softmax function.

  `class Subtract <layers/Subtract.html>`_
  : Layer to subtract two inputs.

  `class UpSampling1D <layers/UpSampling1D.html>`_
  : 1D upsampling layer.

  `class UpSampling2D <layers/UpSampling2D.html>`_
  : 2D upsampling layer.

  `class UpSampling3D <layers/UpSampling3D.html>`_
  : 3D upsampling layer.

  `class ZeroPadding1D <layers/ZeroPadding1D.html>`_
  : 1D zero padding layer.

  `class ZeroPadding2D <layers/ZeroPadding2D.html>`_
  : 2D zero padding layer.

  `class ZeroPadding3D <layers/ZeroPadding3D.html>`_
  : 3D zero padding layer.

.. toctree::
  :hidden:

  layers/Add
  layers/AveragePooling1D
  layers/AveragePooling2D
  layers/AveragePooling3D
  layers/BatchNormalization
  layers/Concatenate
  layers/Conv1D
  layers/Conv1DTranspose
  layers/Conv2D
  layers/Conv2DTranspose
  layers/Conv3D
  layers/Conv3DTranspose
  layers/Dense
  layers/DepthwiseConv2D
  layers/Dropout
  layers/ELU
  layers/Flatten
  layers/GlobalAveragePooling1D
  layers/GlobalAveragePooling2D
  layers/GlobalAveragePooling3D
  layers/GlobalMaxPool1D
  layers/GlobalMaxPool2D
  layers/GlobalMaxPool3D
  layers/Layer
  layers/LeakyReLU
  layers/Maximum
  layers/MaxPool1D
  layers/MaxPool2D
  layers/MaxPool3D
  layers/Minimum
  layers/Multiply
  layers/Permute
  layers/ReLU
  layers/Reshape
  layers/SELU
  layers/Softmax
  layers/Subtract
  layers/UpSampling1D
  layers/UpSampling2D
  layers/UpSampling3D
  layers/ZeroPadding1D
  layers/ZeroPadding2D
  layers/ZeroPadding3D

.. raw:: html

  <style>
  h1:before {
    content: "Module: tf.keras.";
    color: #103d3e;
  }
  </style>
